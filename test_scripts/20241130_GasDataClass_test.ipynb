{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import seaborn as sns\n",
    "from matplotlib.font_manager import FontProperties\n",
    "font1 = FontProperties(fname=r\"C:\\\\Windows\\\\Fonts\\\\STZHONGS.ttf\", size=14)\n",
    "font2 = FontProperties(fname=r\"C:\\\\Windows\\\\Fonts\\\\STZHONGS.ttf\", size=12)\n",
    "font3 = FontProperties(fname=r\"C:\\\\Windows\\\\Fonts\\\\STZHONGS.ttf\", size=10)\n",
    "font4 = FontProperties(fname=r\"C:\\\\Windows\\\\Fonts\\\\STZHONGS.ttf\", size=7)\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette(\"muted\")\n",
    "random.seed(20241120)\n",
    "np.random.seed(20241120)\n",
    "torch.manual_seed(3407) # Torch.manual_seed(3407) is all you need. Paper: http://arxiv.org/abs/2109.08203\n",
    "# 修改工作路径，使本.ipynb文件能够像在本文件夹根目录下一样导入其他模块\n",
    "# Modify the working path so that this.ipynb file can import other modules like in the root directory\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "sys.path.append(os.path.join(current_dir, '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_np.shape: (1124, 30)\n"
     ]
    }
   ],
   "source": [
    "df_whole=pd.read_excel(\"E:\\\\科创优才\\\\实验数据\\\\天然气锅炉数据1.xlsx\", sheet_name=\"稳定运行数据段\")\n",
    "units=df_whole.iloc[0].tolist()\n",
    "df=df_whole.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "# 重命名所有列名，缩短名称长度，方便使用\n",
    "df.columns=[\n",
    "    '开始时间',\n",
    "    '主蒸汽流量计算值',\n",
    "    '烟气含氧量（CEMS）',\n",
    "    '颗粒浓度',\n",
    "    '二氧化硫',\n",
    "    'NO浓度',\n",
    "    'NO2浓度',\n",
    "    'NOX标干浓度',\n",
    "    'NOX浓度',\n",
    "    '烟气湿度（CEMS）',\n",
    "    '烟气压力（CEMS）',\n",
    "    '烟气温度（CEMS）',\n",
    "    '一氧化碳',\n",
    "    '锅炉天然气进气流量',\n",
    "    '锅炉天然气进气温度',\n",
    "    '锅炉天然气进气压力',\n",
    "    '鼓风机出口温度',\n",
    "    '鼓风机出口压力',\n",
    "    '鼓风机变频器输出反馈',\n",
    "    '鼓风机变频器电流反馈',\n",
    "    '再循环烟气调节阀反馈',\n",
    "    '冷凝器出口烟气调节阀反馈',\n",
    "    '炉膛出口烟气温度（B分度）',\n",
    "    '炉膛出口烟气压力',\n",
    "    'SWY大气压',\n",
    "    'SWY天气温度',\n",
    "    'SWY空气湿度',\n",
    "    'SWY湿球温度',\n",
    "    '主蒸汽温度(蒸汽集箱出口温度）',\n",
    "    '主蒸汽压力(蒸汽集箱出口压力）',\n",
    "    '分汽缸温度',\n",
    "    '分汽缸压力',\n",
    "    '分汽缸出口至DN400蒸汽温度',\n",
    "    '过热器集箱出口蒸汽温度',\n",
    "    '天然气累计流量',\n",
    "    '冷凝器烟气流量（累计值）',\n",
    "    '冷凝器出口烟气流量',\n",
    "    '冷凝器出口烟气温度'\n",
    "]\n",
    "\n",
    "# 将可能用到的变量名和单位存入字典\n",
    "var_dict={\n",
    "    \"主蒸汽流量计算值\": \"t/h\",\n",
    "    \"烟气含氧量（CEMS）\": \"mg/Nm3\",\n",
    "    \"NO浓度\": \"mg/Nm3\",\n",
    "    \"NO2浓度\": \"mg/Nm3\",\n",
    "    \"NOX浓度\": \"mg/Nm3\",\n",
    "    \"烟气湿度（CEMS）\": \"%\",\n",
    "    \"烟气压力（CEMS）\": \"Pa\",\n",
    "    \"烟气温度（CEMS）\": \"℃\",\n",
    "    \"一氧化碳\": \"mg/Nm3\",\n",
    "    \"锅炉天然气进气流量\": \"m3/h\",\n",
    "    \"锅炉天然气进气温度\": \"℃\",\n",
    "    \"锅炉天然气进气压力\": \"kPa\",\n",
    "    '鼓风机出口温度': \"℃\",\n",
    "    \"鼓风机出口压力\": \"kPa\",\n",
    "    \"鼓风机变频器输出反馈\": \"Hz\",\n",
    "    \"鼓风机变频器电流反馈\": \"A\",\n",
    "    \"冷凝器出口烟气调节阀反馈\": \"%\",\n",
    "    \"炉膛出口烟气压力\": \"Pa\",\n",
    "    \"SWY大气压\": \"kPa\",\n",
    "    \"SWY天气温度\": \"℃\",\n",
    "    \"SWY空气湿度\": \"%\",\n",
    "    'SWY湿球温度': \"℃\",\n",
    "    '主蒸汽温度(蒸汽集箱出口温度）': \"℃\",\n",
    "    \"主蒸汽压力(蒸汽集箱出口压力）\": \"MPa\",\n",
    "    \"分汽缸温度\": \"℃\",\n",
    "    \"分汽缸压力\": \"MPa\",\n",
    "    '分汽缸出口至DN400蒸汽温度': \"℃\",\n",
    "    '过热器集箱出口蒸汽温度': \"℃\",\n",
    "    \"冷凝器出口烟气流量\": \"Nm3/h\",\n",
    "    \"冷凝器出口烟气温度\": \"℃\",\n",
    "}\n",
    "var_names=list(var_dict.keys())\n",
    "\n",
    "# 定义输入变量\n",
    "input_var_names=[\n",
    "    \"主蒸汽流量计算值\",\n",
    "    \"锅炉天然气进气流量\",\n",
    "    \"锅炉天然气进气温度\",\n",
    "    \"锅炉天然气进气压力\",\n",
    "    '鼓风机出口温度',\n",
    "    \"鼓风机出口压力\",\n",
    "    \"鼓风机变频器输出反馈\",\n",
    "    \"鼓风机变频器电流反馈\",\n",
    "    \"冷凝器出口烟气调节阀反馈\",\n",
    "    \"SWY大气压\",\n",
    "    \"SWY天气温度\",\n",
    "    \"SWY空气湿度\",\n",
    "    'SWY湿球温度',\n",
    "    \"主蒸汽温度(蒸汽集箱出口温度）\",\n",
    "    \"主蒸汽压力(蒸汽集箱出口压力）\",\n",
    "]\n",
    "\n",
    "# 定义输出变量\n",
    "output_var_names=[\n",
    "    \"烟气含氧量（CEMS）\",\n",
    "    #NO浓度\",\n",
    "    #\"NO2浓度\", # 主要预测NO，因为NO2的准确性有待考量\n",
    "    \"NOX浓度\",\n",
    "    \"烟气湿度（CEMS）\",\n",
    "    \"烟气压力（CEMS）\",\n",
    "    \"烟气温度（CEMS）\",\n",
    "    \"一氧化碳\",\n",
    "    \"炉膛出口烟气压力\",\n",
    "\n",
    "    #暂时不考虑以下输出变量\n",
    "    #\"分汽缸温度\",\n",
    "    #\"分汽缸压力\",\n",
    "    #\"分汽缸出口至DN400蒸汽温度\",\n",
    "    #\"过热器集箱出口蒸汽温度\",\n",
    "    #\"冷凝器出口烟气流量\",\n",
    "    #\"冷凝器出口烟气温度\",\n",
    "]\n",
    "\n",
    "input_var_dict={name:var_dict[name] for name in input_var_names}\n",
    "output_var_dict={name:var_dict[name] for name in output_var_names}\n",
    "\n",
    "var_units=list(var_dict.values())\n",
    "input_var_units=list(input_var_dict.values())\n",
    "output_var_units=list(output_var_dict.values())\n",
    "\n",
    "input_var_indices=[var_names.index(name) for name in input_var_names]\n",
    "output_var_indices=[var_names.index(name) for name in output_var_names]\n",
    "\n",
    "\n",
    "data_np=df[var_names].to_numpy(dtype=float)\n",
    "\n",
    "# 通过不同切片增加数据量\n",
    "DATA=[\n",
    "    data_np,\n",
    "    data_np[:20,:],\n",
    "    data_np[:50,:],\n",
    "    data_np[:100,:],\n",
    "    data_np[:800,:],\n",
    "    data_np[100:850,:],\n",
    "    data_np[200:900,:],\n",
    "    data_np[300:950,:],\n",
    "    data_np[400:1000,:],\n",
    "    ]\n",
    "print(\"data_np.shape:\", data_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GasData():\n",
    "\n",
    "    class Utils:\n",
    "        def __init__(self, outer_instance):\n",
    "            self.outer_instance=outer_instance\n",
    "\n",
    "        @staticmethod\n",
    "        def train_test_split(data, train_ratio=0.8, test_ratio=0.2):\n",
    "            '''\n",
    "            Split the dataset into training and testing sets.\n",
    "            '''\n",
    "            assert train_ratio+test_ratio<=1.0, \"train_ratio+test_ratio must be <= 1.0\"\n",
    "            assert type(data)==list, \"`data` must be a list\"\n",
    "            \n",
    "            n_series=len(data)\n",
    "            num_train=int(train_ratio*n_series)\n",
    "            num_test=n_series-num_train\n",
    "\n",
    "            # Randomly split the dataset into training and testing sets\n",
    "            indices=list(range(n_series))\n",
    "            import random\n",
    "            random.shuffle(indices)\n",
    "            train_series_indices=indices[:num_train]\n",
    "            test_series_indices=indices[num_train:num_train+num_test]\n",
    "            data_train = [data[i] for i in train_series_indices]\n",
    "            data_test = [data[i] for i in test_series_indices]\n",
    "\n",
    "            print(\"train data indices:\", train_series_indices)\n",
    "            print(\"test data indices:\", test_series_indices)\n",
    "            print(\"num_train:\", num_train)\n",
    "            print(\"num_test:\", num_test)\n",
    "\n",
    "            return (train_series_indices, test_series_indices), (data_train, data_test)\n",
    "\n",
    "        @staticmethod\n",
    "        def time_series_slice(data, input_len, output_len, input_indices=None, output_indices=None):\n",
    "            r'''\n",
    "\n",
    "            '''\n",
    "            def split_2d_np(np_2d, input_len, output_len):\n",
    "                assert np_2d.ndim==2, \"`np_2d` must be a 2D numpy array\"\n",
    "                n_timesteps, n_vars = np_2d.shape\n",
    "                X = []\n",
    "                Y = []\n",
    "                for i in range(0, n_timesteps-input_len-output_len+1, output_len):\n",
    "                    X.append(np_2d[i:i+input_len,:])\n",
    "                    Y.append(np_2d[i+input_len:i+input_len+output_len,:])\n",
    "                X=np.array(X).astype(\"float32\") # X shape: (N, input_len, n_vars)\n",
    "                Y=np.array(Y).astype(\"float32\") # Y shape: (N, output_len, n_vars)\n",
    "                return X,Y\n",
    "\n",
    "            assert type(data)==list, f\"`data` should be a list, but got {type(data)}\"\n",
    "            assert all([isinstance(item, np.ndarray) for item in data]), \"`data` should be a list of numpy arrays, but got non-numpy array in the list\"\n",
    "            assert all([item.ndim==2 for item in data]), \"`data` must be a list of 2D numpy arrays, but got non-2D item in the list\"\n",
    "            assert all([item.shape[1]==data[0].shape[1] for item in data]), \"All numpy arrays in `data` must have the same number of columns (features)\"\n",
    "            \n",
    "            n_timesteps, n_vars = data[0].shape\n",
    "            input_indices=range(n_vars) if input_indices is None else input_indices\n",
    "            output_indices=range(n_vars) if output_indices is None else output_indices\n",
    "            \n",
    "            X_grouped=[]\n",
    "            Y_grouped=[]\n",
    "            for data_i in data: # data_i: numpy array. Shape: (n_timesteps, n_vars)\n",
    "                X_i, Y_i = split_2d_np(data_i, input_len, output_len)\n",
    "                X_i, Y_i = X_i[:,:,input_indices], Y_i[:,:,output_indices] # Only take the specified input and output variables into X and Y\n",
    "                X_grouped.append(X_i) # X_i shape: (N, input_len, len(input_indices))\n",
    "                Y_grouped.append(Y_i) # Y_i shape: (N, output_len, len(output_indices))\n",
    "\n",
    "            return X_grouped, Y_grouped\n",
    "\n",
    "    def __init__(self, data, input_len, output_len,\n",
    "                    input_indices=None,\n",
    "                    output_indices=None,\n",
    "                    transform_func=None,\n",
    "                    inverse_transform_func=None\n",
    "                    ):\n",
    "        r\"\"\"\n",
    "        :param data: list of numpy arrays of shape: (n_timesteps, n_vars). n_timesteps can be different, but n_vars must be the same.\n",
    "        :param input_len: the length of each input sequence.\n",
    "        :param output_len: the length of each output sequence.\n",
    "        :param input_indices: the indices of the input variables. If None, all variables are used as input variables.\n",
    "        :param output_indices: the indices of the output variables. If None, all variables are used as output variables.\n",
    "        \"\"\"\n",
    "        assert type(data)==list, \"data must be a list\"\n",
    "        assert all([isinstance(item, np.ndarray) for item in data]) and all([item.ndim==2 for item in data]), \"data must be a list of 2D numpy arrays\"\n",
    "        assert all([item.shape[1]==data[0].shape[1] for item in data]), \"All numpy arrays in data must have the same number of columns (features)\"\n",
    "\n",
    "        self.frozen_data = data # save the original data, which is not changed during preprocessing\n",
    "        self.data = data\n",
    "        \n",
    "        self.input_len = input_len\n",
    "        self.output_len = output_len\n",
    "        self.n_series = len(data)\n",
    "        self.n_vars = data[0].shape[1]\n",
    "        self.n_input_vars = self.n_vars if input_indices is None else len(input_indices)\n",
    "        self.n_output_vars = self.n_vars if output_indices is None else len(output_indices)\n",
    "\n",
    "        self.input_indices=range(self.n_vars) if input_indices is None else input_indices\n",
    "        self.output_indices=range(self.n_vars) if output_indices is None else output_indices\n",
    "        self.transform_func = lambda x: x if transform_func is None else transform_func\n",
    "        self.inverse_transform_func = lambda x: x if transform_func is None else inverse_transform_func\n",
    "\n",
    "        self.data_train = None # to be set by `self.train_test_split()`\n",
    "        self.data_test = None # to be set by `self.train_test_split()`\n",
    "        self.train_indices = None # to be set by `self.train_test_split()`\n",
    "        self.test_indices = None # to be set by `self.train_test_split()`\n",
    "\n",
    "        self.X_train_grouped = None # to be set by `self.time_series_slice()`\n",
    "        self.Y_train_grouped = None # to be set by `self.time_series_slice()`\n",
    "        self.X_test_grouped = None # to be set by `self.time_series_slice()`\n",
    "        self.Y_test_grouped = None # to be set by `self.time_series_slice()`\n",
    "        \n",
    "        self.var_mean = None # to be set by `self.standardize()`\n",
    "        self.var_std_dev = None # to be set by `self.standardize()`\n",
    "        self.input_var_mean = None # to be set by `self.standardize()`\n",
    "        self.input_var_std_dev = None # to be set by `self.standardize()`\n",
    "        self.output_var_mean = None # to be set by `self.standardize()`\n",
    "        self.output_var_std_dev = None # to be set by `self.standardize()`\n",
    "        \n",
    "        self.X_train = None # to be set by `self.build_train_test_set()`\n",
    "        self.Y_train = None # to be set by `self.build_train_test_set()`\n",
    "        self.X_test = None # to be set by `self.build_train_test_set()`\n",
    "        self.Y_test = None # to be set by `self.build_train_test_set()`\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "    \n",
    "    # --------The methods below should be called in order--------\n",
    "    # --------If the order is changed, bugs may occur------------\n",
    "\n",
    "    def transform(self):\n",
    "        r'''\n",
    "        Apply a transformation function to each numpy array in the data list.\n",
    "        '''\n",
    "        self.data = [self.transform_func(d) for d in self.data]\n",
    "        return\n",
    "\n",
    "    def standardize(self):\n",
    "        count=np.sum([d.shape[0] for d in self.data]) # total timestep count\n",
    "        var_mean = np.sum([np.sum(d, axis=0) for d in self.data], axis=0)/count\n",
    "        var_std_dev=np.sqrt(np.sum([np.sum((d - var_mean) ** 2, axis=0) for d in self.data], axis=0)/count)\n",
    "        transformed_data = [(d-var_mean)/var_std_dev for d in self.data]\n",
    "        \n",
    "        # Note that `self.data` is changed!\n",
    "        self.data = transformed_data\n",
    "\n",
    "        self.var_mean = var_mean\n",
    "        self.var_std_dev = var_std_dev\n",
    "        self.input_var_mean = var_mean[self.input_indices]\n",
    "        self.input_var_std_dev = var_std_dev[self.input_indices]\n",
    "        self.output_var_mean = var_mean[self.output_indices]\n",
    "        self.output_var_std_dev = var_std_dev[self.output_indices]\n",
    "\n",
    "        print(\"var_mean.shape: \", var_mean.shape)\n",
    "        print(\"var_std_dev.shape: \", var_std_dev.shape)\n",
    "        print(\"var_mean:\", self.var_mean)\n",
    "        print(\"var_std_dev:\", self.var_std_dev)\n",
    "\n",
    "        return transformed_data, var_mean, var_std_dev\n",
    "\n",
    "    def train_test_split(self, train_ratio=0.8, test_ratio=0.2):\n",
    "        (self.train_indices, self.test_indices), (self.data_train, self.data_test) \\\n",
    "            = self.Utils.train_test_split(self.data, train_ratio, test_ratio)\n",
    "\n",
    "    def time_series_slice(self):\n",
    "        r'''\n",
    "        Segment the time series data into input and output sequences.\n",
    "        Need to call `self.train_test_split()` first to split the data into training and testing sets.\n",
    "        '''\n",
    "        assert hasattr(self, \"data_train\") and \\\n",
    "            hasattr(self, \"data_test\"), \\\n",
    "            \"Please call `self.train_test_split()` first to split the data into training and testing sets\"\n",
    "        \n",
    "        self.X_train_grouped, self.Y_train_grouped = self.Utils.time_series_slice(self.data_train, self.input_len, self.output_len, self.input_indices, self.output_indices)\n",
    "        self.X_test_grouped, self.Y_test_grouped = self.Utils.time_series_slice(self.data_test, self.input_len, self.output_len, self.input_indices, self.output_indices)\n",
    "        \n",
    "        print(\"len(X_train_grouped):\", len(self.X_train_grouped))\n",
    "        print(\"len(Y_train_grouped):\", len(self.Y_train_grouped))\n",
    "        print(\"len(X_test_grouped):\", len(self.X_test_grouped))\n",
    "        print(\"len(Y_test_grouped):\", len(self.Y_test_grouped))\n",
    "\n",
    "        return (self.X_train_grouped, self.Y_train_grouped), (self.X_test_grouped, self.Y_test_grouped)\n",
    "\n",
    "    def build_train_test_set(self):\n",
    "        r'''\n",
    "        Get the training and testing sets (Organized as numpy arrays without a outer list) for time series data.\n",
    "        Need to call `self.time_series_slice()` first to split the data into input and output sequences.\n",
    "        '''\n",
    "        assert hasattr(self, \"X_train_grouped\") and \\\n",
    "                hasattr(self, \"Y_train_grouped\") and \\\n",
    "                hasattr(self, \"X_test_grouped\") and \\\n",
    "                hasattr(self, \"Y_test_grouped\"), \\\n",
    "                \"Please call `self.time_series_slice()` first to split the data into input and output sequences\"\n",
    "        \n",
    "        self.X_train=np.concatenate(self.X_train_grouped, axis=0) # shape: (N_train, input_len, len(input_indices))\n",
    "        self.Y_train=np.concatenate(self.Y_train_grouped, axis=0) # shape: (N_train, output_len, len(output_indices))\n",
    "        self.X_test=np.concatenate(self.X_test_grouped, axis=0) # shape: (N_test, input_len, len(input_indices))\n",
    "        self.Y_test=np.concatenate(self.Y_test_grouped, axis=0) # shape: (N_test, output_len, len(output_indices))\n",
    "        \n",
    "        print(\"X_train.shape:\", self.X_train.shape)\n",
    "        print(\"Y_train.shape:\", self.Y_train.shape)\n",
    "        print(\"X_test.shape:\", self.X_test.shape)\n",
    "        print(\"Y_test.shape:\", self.Y_test.shape)\n",
    "        \n",
    "        return (self.X_train, self.Y_train), (self.X_test, self.Y_test)\n",
    "    \n",
    "    # -----------------------------------------\n",
    "    def standardize_2d_np(self, np_2d, mode=\"input\"):\n",
    "        r'''\n",
    "        Use the mean and standard deviation of the whole dataset to standardize a 2D numpy array.\n",
    "        '''\n",
    "        assert isinstance(np_2d, np.ndarray) and np_2d.ndim==2, \"`np_2d` must be a 2D numpy array\"\n",
    "        assert self.var_mean is not None and self.var_std_dev is not None, \\\n",
    "                \"Please call `self.standardize()` first to calculate the mean and standard deviation of the whole dataset\"\n",
    "\n",
    "        if mode==\"input\":\n",
    "            assert np_2d.shape[1]==self.n_input_vars,\\\n",
    "                \"The number of columns (features) of `np_2d` must be the same as the number of input variables in the dataset\"            \n",
    "            return (np_2d - self.input_var_mean) / self.input_var_std_dev\n",
    "        elif mode==\"output\":\n",
    "            assert np_2d.shape[1]==self.n_output_vars,\\\n",
    "                \"The number of columns (features) of `np_2d` must be the same as the number of output variables in the dataset\"\n",
    "            return (np_2d - self.output_var_mean) / self.output_var_std_dev\n",
    "        else:\n",
    "            raise ValueError(\"`mode` must be either 'input' or 'output'\")\n",
    "\n",
    "    def inverse_standardize_2d_np(self, np_2d, mode=\"output\"):\n",
    "        r'''\n",
    "        Use the mean and standard deviation of the whole dataset to inverse standardize a 2D numpy array.\n",
    "        '''\n",
    "        assert isinstance(np_2d, np.ndarray) and np_2d.ndim==2, \"`np_2d` must be a 2D numpy array\"\n",
    "        assert self.var_mean is not None and self.var_std_dev is not None, \\\n",
    "                \"Please call `self.standardize()` first to calculate the mean and standard deviation of the whole dataset\"\n",
    "\n",
    "        if mode==\"output\":\n",
    "            assert np_2d.shape[1]==self.n_output_vars,\\\n",
    "                \"The number of columns (features) of `np_2d` must be the same as the number of output variables in the dataset\"\n",
    "            return np_2d * self.output_var_std_dev + self.output_var_mean\n",
    "        elif mode==\"input\":\n",
    "            assert np_2d.shape[1]==self.n_input_vars,\\\n",
    "                \"The number of columns (features) of `np_2d` must be the same as the number of input variables in the dataset\"\n",
    "            return np_2d * self.input_var_std_dev + self.input_var_mean\n",
    "        else:\n",
    "            raise ValueError(\"`mode` must be either 'input' or 'output'\")\n",
    "    \n",
    "    def inverse_transform_2d_np(self, np_2d):\n",
    "        r'''\n",
    "        Apply the inverse transformation function to a 2D numpy array.\n",
    "        '''\n",
    "        return self.inverse_transform_func(np_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET=GasData(DATA, input_len=10, output_len=3, input_indices=input_var_indices, output_indices=output_var_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data indices: [4, 8, 6, 1, 7, 3, 2]\n",
      "test data indices: [5, 0]\n",
      "num_train: 7\n",
      "num_test: 2\n"
     ]
    }
   ],
   "source": [
    "DATASET.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_mean.shape:  (30,)\n",
      "var_std_dev.shape:  (30,)\n",
      "var_mean: [ 2.06925136e+01  5.29846683e+00  1.16397914e+01  1.62143930e+00\n",
      "  1.32613705e+01  6.15553400e+00 -2.57731081e+01  4.91650563e+01\n",
      "  2.49803087e+00  1.36146592e+03  1.32310847e+01  4.68488840e+01\n",
      "  3.83799583e+01  4.59214643e+00  3.52757906e+01  1.54414176e+02\n",
      "  1.00034873e+02  1.30232791e+00  9.55240718e+01  6.49332499e+00\n",
      "  8.98026700e+01  5.62627034e+00  2.38506277e+02  8.01399666e-01\n",
      "  2.54894501e+02  7.57025448e-01  2.62336099e+02  2.17039846e+02\n",
      "  1.75798102e+01  4.69818356e+01]\n",
      "var_std_dev: [5.25774915e+00 1.12384715e+00 2.77697843e+00 1.98819782e+00\n",
      " 3.29911994e+00 8.07875049e-01 6.49194982e+00 2.70108226e+00\n",
      " 1.43759549e+01 3.45937091e+02 1.02941032e+00 6.44667761e-01\n",
      " 1.79798416e+00 6.67532835e-01 3.38456754e+00 3.13512112e+01\n",
      " 1.24975791e-02 7.52194345e-01 2.01818040e-01 1.73927888e+00\n",
      " 1.44895581e+01 9.53526721e-01 6.32014026e+00 4.23301983e-02\n",
      " 6.34010834e+00 3.95721351e-02 6.39412758e+00 5.11072798e+00\n",
      " 2.49742300e+01 1.90122380e+00]\n"
     ]
    }
   ],
   "source": [
    "transformed_data, var_mean, var_std_dev = DATASET.standardize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_train_grouped): 7\n",
      "len(Y_train_grouped): 7\n",
      "len(X_test_grouped): 2\n",
      "len(Y_test_grouped): 2\n"
     ]
    }
   ],
   "source": [
    "(X_train_grouped, Y_train_grouped), (X_test_grouped, Y_test_grouped) = DATASET.time_series_slice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (1306, 10, 15)\n",
      "Y_train.shape: (1306, 3, 7)\n",
      "X_test.shape: (259, 10, 15)\n",
      "Y_test.shape: (259, 3, 7)\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = DATASET.build_train_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
